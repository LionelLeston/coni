library(boot)
library(dplyr)
library(gamm4)
library(ggplot2)
library(grid)
library(gridExtra)
library(jpeg)
library(lme4)
library(lubridate)
library(mgcv)
library(MuMIn)
library(plotly)
library(pROC)
library(tidyr)
library(unmarked)


my.theme <- theme_classic() +
  theme(text=element_text(size=10, family="Arial"),
        axis.text.x=element_text(size=10),
        axis.text.y=element_text(size=10),
        axis.title.x=element_text(margin=margin(10,0,0,0)),
        axis.title.y=element_text(margin=margin(0,10,0,0)),
        axis.line.x=element_line(linetype=1),
        axis.line.y=element_line(linetype=1))

# function to obtain random samples stratified by site 
#cannot stratify by 2-week periods because after excluding sites
#without temperature readings one site (13577)
#only had samples from 2 nights within 1 2-week period
fSampleNint <- function(dat, intervals, n) {
  intervals <- enquo(intervals)
  dat %>%
    group_by(sm_id)%>%
    filter(UQ(intervals) %in% sample(unique(UQ(intervals)), n)) %>%
    slice(sample(row_number()))
}#dropped season because after removing nights without temperature
#at least one site only had 2 nights available.
#I could add twilight period to ensure even distribution of samples
#throughout the night. If I do so, then 6 sites will have fewer
#samples because they lack intervals from "Night" and "Astronomical"
#periods on nights with temperature data. All 6 sites
#are northern sites


boomsint<-read.csv("0_data/processed/3_BoomsMapped_SunAndMoon/TempSunMoonBoomDetections.10min.int.csv", header=TRUE)
str(boomsint)
boomsint$BOOMS<-ifelse(is.na(boomsint$eventID),0,1)
boomsint$halfmonth<-ifelse(boomsint$day<16,"1","2")
boomsint$season<-as.factor(paste0(boomsint$month,"_",boomsint$halfmonth))

boomsint$start_time_new<- ymd_hms(as.character(boomsint$start_time_new))
boomsint$julian<-yday(as.Date(boomsint$date))
boomsint$hour<-hour(boomsint$start_time_new)
boomsint$minute<-minute(boomsint$start_time_new)
boomsint$start_time_numeric<-boomsint$hour+(boomsint$minute/60)

boomsint$TSSS.s<-scale(boomsint$TSSS, center=FALSE, scale=TRUE)#scaled to reduce rank deficiency of GAMMs
boomsint$ordinal.s<-scale(as.vector(boomsint$julian), center=FALSE, scale=TRUE)#scaled to reduce rank deficiency of GAMMs
boomsint$latitude.s<-scale(boomsint$latitude, center=FALSE, scale=TRUE)#scaled to reduce rank deficiency of GAMMs
boomsint$meantemp.s<-scale(boomsint$meantemp, center=FALSE, scale=TRUE)#not currently being used in these GAMMs
#boomsint$moon.s<-scale(boomsint$moon.fraction, center=FALSE, scale=TRUE)#not currently being used in these GAMMs


boomsint$sm_id<-as.factor(boomsint$sm_id)
boomsint$intervals<-as.factor(boomsint$intervals)
boomsintB<-boomsint[!boomsint$month==8,]#drop August
boomsintC<-boomsintB[!is.na(boomsintB$meantemp),]#drop intervals missing temperature boomsint
maxdur<-max(boomsintC$duration)
boomsintD<-boomsintC[boomsintC$duration==maxdur,]#gets rid of any "remainder" intervals

#this is the point where I could split into training and testing data for purposes of validation
#training data is what I draw samples from
#the test data is then summarized separately afterwards
#and predictions are generated by creating a test data 
#model matrix and matrix-multiplying it with each column of
#bootstrapped coefficients to get 1 column of predictions
#I then graph the observed:predicted relationship and get
#R-squared or correlation coefficient

#I then get a column of predicted values for each bootstrap that I can compare to actual numbers counted
nrow(boomsintD)#26792
boomsintD$sm_id.interval<-as.factor(paste0(boomsintD$sm_id,boomsintD$intervals))
boomsintD.test <- fSampleNint(boomsintD, intervals, 10)
nrow(boomsintD.test)#402;424
boomsintD.train  <- boomsintD[!boomsintD$sm_id.interval %in% boomsintD.test$sm_id.interval,]
nrow(boomsintD.train)#26390;26368

d<-fSampleNint(boomsintD.train, intervals, 10)


booms.pervisit<-d %>%
  group_by(sm_id, intervalsP) %>% 
  summarize(numdetect= sum(BOOMS), 
            duration=mean(duration_new),
            TSSS=mean(TSSScorr), 
            TSSS.s=mean(TSSS.s), 
            meantemp=mean(meantemp),
            meantemp.s=mean(meantemp.s),
            twilightperiod=names(which.max(table(twilightperiod))),
            latitude=mean(latitude),
            latitude.s=mean(latitude.s),
            longitude=mean(longitude),
            #moon.fraction=mean(fraction),
            date=names(which.max(table(date))),
            ordinal.day=mean(julian),
            ordinal.s=mean(ordinal.s),
            time=mean(start_time_numeric))
write.csv(booms.pervisit, file="0_data/processed/4B_BoomActivityRates_GAMMs/temp/boomspervisit.csv")
#confirms that after summarizing I have 20 sample observations per site
#at this point, I can run mixed-effects models or GAMMs

#GAMM

#basic model for 10-minute peent intervals
booms.pervisit$latgroupN<-as.factor(ifelse(booms.pervisit$latitude>55,"N","S"))

mean(booms.pervisit$numdetect)  
var(booms.pervisit$numdetect)  
thetaval=(var(booms.pervisit$numdetect)/mean(booms.pervisit$numdetect))

full.GAM.SS <- gamm4(numdetect ~latgroupN + s(meantemp.s, k = 4, bs = "cs", by=latgroupN) + s(ordinal.s, k = 4, bs = "cs", by=latgroupN) + s(TSSS.s, k = 4, bs = "cs", by=latgroupN), random=~(1|sm_id), data=booms.pervisit, family=negbin(theta=thetaval, link="log"))
plot.gam(full.GAM.SS$gam, main = "Smoothed Untransformed Boom Activity Estimates")
coef.gamm<-coef(full.GAM.SS$gam)
df<-data.frame(coef.gamm)
#write.csv(df, file="3_output/data/4B_BoomGAMMS/GAMMpeents.10min.int.csv")

#Now create the bootstrap
bs <- function(data, indices){
  d<-fSampleNint(data, intervals, 10)
  
  booms.pervisit<-d %>%
    group_by(sm_id, intervalsP) %>% 
    summarize(numdetect= sum(BOOMS), 
              duration=mean(duration_new),
              TSSS=mean(TSSScorr), 
              TSSS.s=mean(TSSS.s), 
              meantemp=mean(meantemp),
              meantemp.s=mean(meantemp.s),
              twilightperiod=names(which.max(table(twilightperiod))),
              latitude=mean(latitude),
              latitude.s=mean(latitude.s),
              longitude=mean(longitude),
              #moon.fraction=mean(fraction),
              date=names(which.max(table(date))),
              ordinal.day=mean(julian),
              ordinal.s=mean(ordinal.s),
              time=mean(start_time_numeric))
  
  #GAMM

  #basic model for 10-minute peent intervals
  booms.pervisit$latgroupN<-as.factor(ifelse(booms.pervisit$latitude>55,"N","S"))
  
  mean(booms.pervisit$numdetect)  
  var(booms.pervisit$numdetect)  
  thetaval=(var(booms.pervisit$numdetect)/mean(booms.pervisit$numdetect))
  
  full.GAM.SS <- gamm4(numdetect ~latgroupN + s(meantemp.s, k = 4, bs = "cs", by=latgroupN) + s(ordinal.s, k = 4, bs = "cs", by=latgroupN) + s(TSSS.s, k = 4, bs = "cs", by=latgroupN), random=~(1|sm_id), data=booms.pervisit, family=negbin(theta=thetaval, link="log"))
  #plot.gam(full.GAM.SS$gam, main = "Smoothed Untransformed Boom Activity Estimates")
  coef.gamm<-coef(full.GAM.SS$gam)
  return(coef.gamm)
}

#boom.all<-read.csv("0_data/processed/3_BoomsMapped_SunAndMoon/TempSunMoonBoomDetections.10min.int.csv", header=TRUE)

boomresults <- boot(data=boomsintD.train,
                    statistic=bs, parallel="multicore",
                    R=100)
#print(paste0("bootstraps successfully run for ",fn))

CoefB <-t(boomresults$t)
#get rid of columns with errors
CoefB<-data.frame(CoefB)
CoefB[] <- lapply(CoefB, function(x) as.numeric(as.character(x)))
#delete columns with NA values
all_na <- function(x) any(!is.na(x))
CoefB<-CoefB %>% select_if(all_na)
CoefB<-as.matrix(CoefB)
ncol(CoefB)
CoefBCI50 <- t(apply(CoefB, 1, quantile, c(0.5, 0.25, 0.75), na.rm=TRUE))
CoefBCI90 <- t(apply(CoefB, 1, quantile, c(0.5, 0.05, 0.95), na.rm=TRUE))
save(boomresults, CoefB, CoefBCI50, CoefBCI90, file="3_output/data/4B_May_BootstrappedBoomGAMMs/boot10samples10minuteintBooms_M14.RData")
#save as csv
df<-data.frame(CoefB)
row.names(df) = c("(Intercept)","latgroupNS","s(meantemp.s):latgroupNN.1",
                  "s(meantemp.s):latgroupNN.2","s(meantemp.s):latgroupNN.3","s(meantemp.s):latgroupNS.1",
                  "s(meantemp.s):latgroupNS.2","s(meantemp.s):latgroupNS.3","s(ordinal.s):latgroupNN.1",
                  "s(ordinal.s):latgroupNN.2","s(ordinal.s):latgroupNN.3","s(ordinal.s):latgroupNS.1",
                  "s(ordinal.s):latgroupNS.2","s(ordinal.s):latgroupNS.3","s(TSSS.s):latgroupNN.1",
                  "s(TSSS.s):latgroupNN.2","s(TSSS.s):latgroupNN.3","s(TSSS.s):latgroupNS.1",
                  "s(TSSS.s):latgroupNS.2","s(TSSS.s):latgroupNS.3")
write.csv(df, file="3_output/data/4B_May_BootstrappedBoomGAMMs/boot10samples10minuteintBooms_M14.csv")
#print(paste0("bootstrap coefficients saved for ",fn))

## box plot of variables with confidence intervals
prednames = c("(Intercept)","latgroupNS","s(meantemp.s):latgroupNN.1",
              "s(meantemp.s):latgroupNN.2","s(meantemp.s):latgroupNN.3","s(meantemp.s):latgroupNS.1",
              "s(meantemp.s):latgroupNS.2","s(meantemp.s):latgroupNS.3","s(ordinal.s):latgroupNN.1",
              "s(ordinal.s):latgroupNN.2","s(ordinal.s):latgroupNN.3","s(ordinal.s):latgroupNS.1",
              "s(ordinal.s):latgroupNS.2","s(ordinal.s):latgroupNS.3","s(TSSS.s):latgroupNN.1",
              "s(TSSS.s):latgroupNN.2","s(TSSS.s):latgroupNN.3","s(TSSS.s):latgroupNS.1",
              "s(TSSS.s):latgroupNS.2","s(TSSS.s):latgroupNS.3")
var.bci<-CoefBCI90
var.bci<-data.frame(var.bci)
var.bci$median<-as.numeric(var.bci$X50.)
var.bci$lcl<-as.numeric(var.bci$X5.)
var.bci$ucl<-as.numeric(var.bci$X95.)
var.bci$prednames<-prednames

GG<-ggplot(var.bci, aes(x=prednames, y=median))+
  geom_point(aes(x=prednames, y=median))+
  geom_errorbar(aes(ymin=lcl,ymax=ucl))+
  geom_hline(yintercept=0)+
  xlab("Predictor")+
  ylab("Effect on booms counted")+coord_flip()+my.theme
ggsave("3_output/figures/4B_May_BootstrappedBoomGAMMs/boot10visits10minuteintervalBoom_M14.jpeg", plot=GG, width=12, height=6, units=c("in"), dpi=300)

#To get GAMM predictions within a bootstrap:
#https://gist.github.com/davharris/3da3a43f3d45ce01ee20

## make data for prediction - TSSS
plotTSSSData<-boomsintD.train[order(boomsintD.train$TSSScorr),]#read.csv("0_data/processed/10B_BoomBootstraps/plotTSSSData.csv",header=TRUE)
plotOrdinalData<-boomsintD.train[order(boomsintD.train$julian),]#read.csv("0_data/processed/10B_BoomBootstraps/plotOrdinalData.csv",header=TRUE)

#Pick southern site, Ordinal day 180
plotTSSSDataS<-plotTSSSData[plotTSSSData$sm_id==8246,]
plotTSSSDataS<-plotTSSSDataS[plotTSSSDataS$julian==180,]

New.TSSS1 <- plotTSSSDataS[,c("sm_id","latitude","latitude.s",
                              "julian","ordinal.s",
                              "TSSS","TSSS.s",
                              "meantemp","meantemp.s")]
New.TSSS1$latgroupN<-as.factor(ifelse(New.TSSS1$latitude>55,"N","S"))
## model matrix that'll match the coefficients
Xnew.TSSS1mm <- model.matrix(full.GAM.SS$gam, New.TSSS1)#meantemp.s+moon.s+


## predict and apply inverse link function: this gives an n_new x B+1 matrix
PredB.S <- (exp(Xnew.TSSS1mm %*% CoefB))

## calculate median and 50% CIs
PredS <- t(apply(PredB.S, 1, quantile, c(0.5, 0.05, 0.95), na.rm=TRUE))


#Pick northern site, Ordinal day 160
plotTSSSDataN<-plotTSSSData[plotTSSSData$sm_id==13588,]
plotTSSSDataN<-plotTSSSDataN[plotTSSSDataN$julian==176,]#June 25 survey date

New.TSSS2 <- plotTSSSDataN[,c("sm_id","latitude","latitude.s",
                              "julian","ordinal.s",
                              "TSSS","TSSS.s",
                              "meantemp","meantemp.s")]
New.TSSS2$latgroupN<-as.factor(ifelse(New.TSSS2$latitude>55,"N","S"))
Xnew.TSSS2mm <- model.matrix(full.GAM.SS$gam, New.TSSS2)#meantemp.s+moon.s+

## predict and apply inverse link function: this gives an n_new x B+1 matrix
PredB.N <- (exp(Xnew.TSSS2mm %*% CoefB))

## calculate median and 50% CIs
PredN <- t(apply(PredB.N, 1, quantile, c(0.5, 0.05, 0.95), na.rm=TRUE))

## plot
tiff("3_output/figures/4B_May_BootstrappedBoomGAMMs/testGAMMmatplotTSSS_M14.tiff", units="in", width=8, height=8, res=300)
par(mfrow=c(2,2))
matplot(plotTSSSDataS$TSSScorr, 
        PredB.S, 
        type="l", 
        xlab="TSSS (Day 180)",
        ylab="Booms Counted 10 min Site 8246")
matplot(plotTSSSDataS$TSSScorr, 
        PredS, 
        type="l", 
        lty=c(1,2,2), 
        col=1,
        xlab="TSSS (Day 180)",
        ylab="Booms Counted 10 min Site 8246")

matplot(plotTSSSDataN$TSSScorr, 
        PredB.N, 
        type="l", 
        xlab="TSSS (Day 160)",
        ylab="Booms Counted 10 min Site 13588")
matplot(plotTSSSDataN$TSSScorr, 
        PredN, 
        type="l", 
        lty=c(1,2,2), 
        col=1,
        xlab="TSSS (Day 160)",
        ylab="Booms Counted 10 min Site 13588")
dev.off()
print("TSSS line plots for bootstrap predictions saved")

#Pick southern site, TSSS=0
plotOrdinalDataS<-plotOrdinalData[plotOrdinalData$sm_id==8246,]
plotOrdinalDataS<-plotOrdinalDataS[plotOrdinalDataS$TSSS==0,]

New.Ordinal1 <- plotOrdinalDataS[,c("sm_id","latitude","latitude.s",
                              "julian","ordinal.s",
                              "TSSS","TSSS.s",
                              "meantemp","meantemp.s")]
New.Ordinal1$latgroupN<-as.factor(ifelse(New.Ordinal1$latitude>55,"N","S"))
## model matrix that'll match the coefficients
Xnew.Ordinal1mm <- model.matrix(full.GAM.SS$gam, New.Ordinal1)#meantemp.s+moon.s+


## predict and apply inverse link function: this gives an n_new x B+1 matrix
PredB.S <- (exp(Xnew.Ordinal1mm %*% CoefB))

## calculate median and 50% CIs
PredS <- t(apply(PredB.S, 1, quantile, c(0.5, 0.05, 0.95), na.rm=TRUE))


#Pick northern site, TSSS=0
plotOrdinalDataN<-plotOrdinalData[plotOrdinalData$sm_id==13588,]
plotOrdinalDataN<-plotOrdinalDataN[plotOrdinalDataN$TSSS==0,]

New.Ordinal2 <- plotOrdinalDataN[,c("latitude","latitude.s",
                              "julian","ordinal.s",
                              "TSSS","TSSS.s",
                              "meantemp","meantemp.s")]
New.Ordinal2$latgroupN<-as.factor(ifelse(New.Ordinal2$latitude>55,"N","S"))
Xnew.Ordinal2mm <- model.matrix(full.GAM.SS$gam, New.Ordinal2)#meantemp.s+moon.s+

## predict and apply inverse link function: this gives an n_new x B+1 matrix
PredB.N <- (exp(Xnew.Ordinal2mm %*% CoefB))

## calculate median and 90% CIs
PredN <- t(apply(PredB.N, 1, quantile, c(0.5, 0.05, 0.95), na.rm=TRUE))

## plot
tiff("3_output/figures/4B_May_BootstrappedBoomGAMMs/testGAMMmatplotOrdinal_M14.tiff", units="in", width=8, height=8, res=300)
par(mfrow=c(2,2))
matplot(plotOrdinalDataS$julian, 
        PredB.S, 
        type="l", 
        xlab="Ordinal day (TSSS=0)",
        ylab="Booms per 10 min Site 8246")
matplot(plotOrdinalDataS$julian, 
        PredS, 
        type="l", 
        lty=c(1,2,2), 
        col=1,
        xlab="Ordinal day (TSSS=0)",
        ylab="Booms per 10 min Site 8246")

matplot(plotOrdinalDataN$julian, 
        PredB.N, 
        type="l", 
        xlab="Ordinal day (TSSS=0)",
        ylab="Booms per 10 min Site 13588")
matplot(plotOrdinalDataN$julian, 
        PredN, 
        type="l", 
        lty=c(1,2,2), 
        col=1,
        xlab="Ordinal day (TSSS=0)",
        ylab="Booms per 10 min Site 13588")
dev.off()
print("Ordinal day line plots for bootstrap predictions saved")

#same data for plotting temperature relationship as ordinal day relationship;
#just sorted by temperature instead
plotTempData<-boomsintD.train[order(boomsintD.train$meantemp),]

#Pick southern site, TSSS=0
plotTempDataS<-plotTempData[plotTempData$sm_id==8246,]
plotTempDataS<-plotTempDataS[plotTempDataS$TSSS==0,]

New.Temp1 <- plotTempDataS[,c("sm_id","latitude","latitude.s",
                                    "julian","ordinal.s",
                                    "TSSS","TSSS.s",
                                    "meantemp","meantemp.s")]
New.Temp1$latgroupN<-as.factor(ifelse(New.Temp1$latitude>55,"N","S"))
## model matrix that'll match the coefficients
Xnew.Temp1mm <- model.matrix(full.GAM.SS$gam, New.Temp1)#meantemp.s+moon.s+


## predict and apply inverse link function: this gives an n_new x B+1 matrix
PredB.S <- (exp(Xnew.Temp1mm %*% CoefB))

## calculate median and 50% CIs
PredS <- t(apply(PredB.S, 1, quantile, c(0.5, 0.05, 0.95), na.rm=TRUE))


#Pick northern site, TSSS=0
plotTempDataN<-plotTempData[plotTempData$sm_id==13588,]
plotTempDataN<-plotTempDataN[plotTempDataN$TSSS==0,]

New.Temp2 <- plotTempDataN[,c("latitude","latitude.s",
                                    "julian","ordinal.s",
                                    "TSSS","TSSS.s",
                                    "meantemp","meantemp.s")]
New.Temp2$latgroupN<-as.factor(ifelse(New.Temp2$latitude>55,"N","S"))
Xnew.Temp2mm <- model.matrix(full.GAM.SS$gam, New.Temp2)#meantemp.s+moon.s+

## predict and apply inverse link function: this gives an n_new x B+1 matrix
PredB.N <- (exp(Xnew.Temp2mm %*% CoefB))

## calculate median and 90% CIs
PredN <- t(apply(PredB.N, 1, quantile, c(0.5, 0.05, 0.95), na.rm=TRUE))


## plot
tiff("3_output/figures/4B_May_BootstrappedBoomGAMMs/testGAMMmatplotTemperature_M14.tiff", units="in", width=8, height=8, res=300)
par(mfrow=c(2,2))
matplot(plotTempDataS$meantemp, 
        PredB.S, 
        type="l", 
        xlab="Mean Nightly Temperature",
        ylab="Booms per 10 min Site 8246")
matplot(plotTempDataS$meantemp, 
        PredS, 
        type="l", 
        lty=c(1,2,2), 
        col=1,
        xlab="Mean Nightly Temperature",
        ylab="Booms per 10 min Site 8246")

matplot(plotTempDataN$meantemp, 
        PredB.N, 
        type="l", 
        xlab="Mean Nightly Temperature",
        ylab="Booms per 10 min Site 13588")
matplot(plotTempDataN$meantemp, 
        PredN, 
        type="l", 
        lty=c(1,2,2), 
        col=1,
        xlab="Mean Nightly Temperature",
        ylab="Booms per 10 min Site 13588")
dev.off()
print("Temperature line plots for bootstrap predictions saved")


#Validating the GAMMS, using the test data from earlier
#i.e. boomsintD.test, which still must be summarized by interval
booms.pervisit.test<-boomsintD.test %>%
  group_by(sm_id, intervalsP) %>% 
  summarize(numdetect= sum(BOOMS), 
            duration=mean(duration_new),
            TSSS=mean(TSSScorr), 
            TSSS.s=mean(TSSS.s), 
            meantemp=mean(meantemp),
            meantemp.s=mean(meantemp.s),
            twilightperiod=names(which.max(table(twilightperiod))),
            latitude=mean(latitude),
            latitude.s=mean(latitude.s),
            longitude=mean(longitude),
            #moon.fraction=mean(fraction),
            date=names(which.max(table(date))),
            ordinal.day=mean(julian),
            ordinal.s=mean(ordinal.s),
            time=mean(start_time_numeric))

booms.pervisit.test$latgroupN<-as.factor(ifelse(booms.pervisit.test$latitude>55,"N","S"))
## model matrix that'll match the coefficients
Xnew.Test.mm <- model.matrix(full.GAM.SS$gam, booms.pervisit.test)

## predict and apply inverse link function: this gives an n_new x B+1 matrix
Preds <- (exp(Xnew.Test.mm %*% CoefB))

booms.pervisit.test.df<-data.frame(booms.pervisit.test)
Preds.df<-data.frame(Preds)
TestDatapreds<-cbind(booms.pervisit.test.df, Preds.df)

str(TestDatapreds)
write.csv(TestDatapreds, file="3_output/data/4B_May_BootstrappedBoomGAMMs/TestDatapreds.csv")

spearmancorlist<-list()
names<-c("X1","X2","X3","X4","X5","X6","X7","X8","X9","X10",
         "X11","X12","X13","X14","X15","X16","X17","X18","X19","X20",
         "X21","X22","X23","X24","X25","X26","X27","X28","X29","X30",
         "X31","X32","X33","X34","X35","X36","X37","X38","X39","X40",
         "X41","X42","X43","X44","X45","X46","X47","X48","X49","X50",
         "X51","X52","X53","X54","X55","X56","X57","X58","X59","X60",
         "X61","X62","X63","X64","X65","X66","X67","X68","X69","X70",
         "X71","X72","X73","X74","X75","X76","X77","X78","X79","X80",
         "X81","X82","X83","X84","X85","X86","X87","X88","X89","X90",
         "X91","X92","X93","X94","X95","X96","X97","X98","X99","X100")
for (i in names){
  TestDatapreds$Predicted<-TestDatapreds[,i]
  spearmancorlist[[i]]<-cor(TestDatapreds$numdetect, TestDatapreds$Predicted, method="spearman")
}
spearmancorvec<-unlist(spearmancorlist)
spearmandf<-data.frame(spearmancorvec)
## calculate median and 90% CIs
RhoN <-quantile(spearmancorvec, c(0.5, 0.05, 0.95), na.rm=TRUE)
#       50%         5%        95% 
#0.1790404 0.0356654 0.3023125 




